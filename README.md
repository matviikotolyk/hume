# Hume Personal Therapist

### Chat about your journal entries or complete a guided meditation session. Learn more about yourself and your emotions.

### Inspiration

I have been journalling and meditating on and off throughout the recent few years and have always found benefit in having these habits as part of my daily routine. I would typically slip off because I wouldn't have an "accountability buddy" and I would forget to keep doing these on my own. I thought that guided meditations would be a great use case for Hume AI's EVI model. While there are still some limitations in order to fully replicate the experience of meditation, the model is surprisingly good at acting as a meditation guide. I also found EVI to be a great way to analyze my journal entries and gain insights into my emotional state.

### What it does

The users have two main options: go through the guided meditation session or chat about their journal entries with the EVI model. When starting a conversation, the custom EVI leads the interaction by asking the user how they feel and if they want to do a guided meditation session. The assistant then follows up with a few questions to customize the meditation sessions and guides the user through the proceess.
Additionally, the user can upload a journal entry and the app will analyze the emotional state of the entry and provide insights into the user's emotional state. They can select it to be part of the context for the EVI model which then allows the model to refer to the content of the entry. The user can ask for suggestions and tips regarding wellness and lifestyle and the model will use the web search tool to return responses. Furthermore, by clicking Web Search, the user initiates a Google search query based on the response generated by the assistant. This reduces the friction of having to search for information on their own and allows the user to get more information about their emotional state.

### How we built it

I started by creating a Next.js app with create-t3-app. I then added the Voice SDK and the Supabase auth and database to the app. I also added the Groq SDK to the app to use llama on groq to analyze the content of the uploaded pdf file. I used the pdf.js library to parse the pdf file and extract the text. Next, I added a landing page that allows the user to upload a journal entry and analyze it. Ensuring that uploading the PDF file works took the longest and required using a few technologies at the same time.

### Challenges we ran into

- The main challenge I ran into is making the EVI model sounds similar to an actual human meditation guide. I had to tweak the prompts and the system prompt to make it sound more like a guided meditation. I was going to integrate the resumeAssistant and pauseAssistant functions from the Voice SDK to make it more interactive, but haven't implemented it yet as the wait would sometimes be too long and make the user disengaged from the normal interaction. Overall, the model is very realistic and it's going to be about further tweaks to improve the UX.

### Accomplishments that we're proud of

- PDF parser with llama on groq analyzing the content of the pdf and then passing it to the EVI model as a system prompt. This combines different technologies to create a feature that is both powerful and easy to use.
- Search results using Google Search API based on the query generated by llama on groq from the assistant's inputs.
- User friendly UI that makes it fairly easy for the user to start interacting with the app.
- Llama on Groq integration to analyze the content of the pdf and pass it to the EVI model as a system prompt.

### What we learned

- I used supabase auth for the first time; learned to use Hume's EVI API; used Google Search API to get search results; used Twilio Sendgrid to send signup emails; learned how to use Groq SDK to use llama to analyze the contents of a pdf file; learned how to parse a PDF using the pdf.js library.

### What's next for Journova

First things first, I will double verify the auth is working end-to-end. I will also improve how the search results are displayed, making it more Perplexity-like to improve usability and value. Next, I will make the app more multimodal exploring other types of things users can chat about, like their moods, their goals, and their dreams. Additionally, I will add an option to chat via keyboard input since some users may not be super comfortable talking about their feelings. Moreover, it will enhance the app's accessibility and usability for users with disabilities. Finally, I will work on creating a simple mobile app that has the same functionality but a very simple UI to interact with EVI.

### Built With

Next.js, Supabase, Groq, React, Radix UI, TypeScript, Tailwind CSS, Twilio Sendgrid, Google Search API, and Google Search Engine ID
